{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc49ee4-a0a5-4937-8b07-05efd280d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 21:27:40,435\tWARNING services.py:404 -- Found multiple active Ray instances: {'10.244.0.5:6380', 'service-ray-cluster:6380', '192.168.3.51:6378'}. Connecting to latest cluster at 192.168.3.51:6378. You can override this by setting the `--address` flag or `RAY_ADDRESS` environment variable.\n",
      "2023-06-15 21:27:40,436\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 192.168.3.51:6378...\n",
      "2023-06-15 21:27:40,449\tINFO worker.py:1616 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-06-15 21:27:51,406\tWARNING read_api.py:358 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# Load data.\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# Split data into train and validation.\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Create a test dataset by dropping the target column.\n",
    "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21916544-867e-4e03-b18a-b1c28e9116e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    # Number of workers to use for data parallelism.\n",
    "    num_workers=1,\n",
    "    # Whether to use GPU acceleration.\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c07fbe-60de-4655-b714-89e7852314e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=scaling_config,\n",
    "    label_column=\"target\",\n",
    "    num_boost_round=20,\n",
    "    params={\n",
    "        # XGBoost specific params\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"gpu_hist\",  # uncomment this to use GPU for training\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46fb2fa8-046c-47d1-99a0-3e44691b95c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-15 21:32:49</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.34        </td></tr>\n",
       "<tr><td>Memory:      </td><td>25.0/62.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T600)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_19cff_00000</td><td>TERMINATED</td><td>192.168.3.51:730760</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         6.04572</td><td style=\"text-align: right;\">      0.0185789</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0.0873526</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m /home/modongsong/.pyenv/versions/miniconda3-4.7.12/envs/jupyterlab/lib/python3.10/site-packages/xgboost_ray/main.py:512: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=730018)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=730830)\u001b[0m [21:32:45] task [xgboost.ray]:140180960923936 got new rank 0\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:47] WARNING: ../src/gbm/gbtree.cc:415: \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   machine. Consider using `save_model/load_model` instead. See:\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m     https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:47] WARNING: ../src/gbm/gbtree.cc:425: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:47] WARNING: ../src/learner.cc:339: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip     </th><th style=\"text-align: right;\">   pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  valid-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_19cff_00000</td><td>2023-06-15_21-32-49</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>mds-hp    </td><td style=\"text-align: right;\">                        21</td><td>192.168.3.51</td><td style=\"text-align: right;\">730760</td><td>True               </td><td style=\"text-align: right;\">             6.04572</td><td style=\"text-align: right;\">          0.261944</td><td style=\"text-align: right;\">       6.04572</td><td style=\"text-align: right;\"> 1686835969</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0.0185789</td><td style=\"text-align: right;\">                  21</td><td>19cff_00000</td><td style=\"text-align: right;\">    0.0350877</td><td style=\"text-align: right;\">      0.0873526</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:48] WARNING: ../src/gbm/gbtree.cc:415: \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   machine. Consider using `save_model/load_model` instead. See:\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m     https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m   for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:48] WARNING: ../src/gbm/gbtree.cc:425: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=730760)\u001b[0m [21:32:48] WARNING: ../src/learner.cc:339: No visible GPU is found, setting `gpu_id` to -1\n",
      "2023-06-15 21:32:49,032\tINFO tune.py:945 -- Total run time: 8.35 seconds (8.34 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train-logloss': 0.01857892927496071, 'train-error': 0.0, 'valid-logloss': 0.08735255994942932, 'valid-error': 0.03508771929824561, 'time_this_iter_s': 0.261944055557251, 'should_checkpoint': True, 'done': True, 'training_iteration': 21, 'trial_id': '19cff_00000', 'date': '2023-06-15_21-32-49', 'timestamp': 1686835969, 'time_total_s': 6.045717239379883, 'pid': 730760, 'hostname': 'mds-hp', 'node_ip': '192.168.3.51', 'config': {}, 'time_since_restore': 6.045717239379883, 'iterations_since_restore': 21, 'experiment_tag': '0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 21:52:53,221\tWARNING worker.py:1986 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/home/modongsong/.pyenv/versions/miniconda3-4.7.12/envs/jupyterlab/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 674, in <module>\n",
      "    monitor.run()\n",
      "  File \"/home/modongsong/.pyenv/versions/miniconda3-4.7.12/envs/jupyterlab/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 550, in run\n",
      "    self._run()\n",
      "  File \"/home/modongsong/.pyenv/versions/miniconda3-4.7.12/envs/jupyterlab/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py\", line 454, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n",
      "[2023-06-15 21:52:53,388 E 729506 729609] core_worker.cc:569: :info_message: Attempting to recover 17 lost objects by resubmitting their tasks. To disable object reconstruction, set @ray.remote(max_retries=0).\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700a03a-e402-4221-8acb-2d5958172f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
